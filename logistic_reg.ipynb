{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"logistic_reg.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPJ4QjN6dslsNwPePgUILZD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P71GEBsSQ0ia","executionInfo":{"status":"ok","timestamp":1643263698267,"user_tz":-480,"elapsed":1382,"user":{"displayName":"Tsz Chun Leung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03041754811113981543"}},"outputId":"bdb6f0d8-7101-49e2-ed63-8a7b8598f9f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["(0.6918123275068997, 0.7224264705882353, array([0.67586207, 0.69241379, 0.69889503]), 0.0)\n","(0.6826126954921803, 0.7077205882352942, array([0.67310345, 0.71034483, 0.69475138]), 0.0)\n","(0.6922723091076357, 0.71875, array([0.65241379, 0.70896552, 0.69475138]), 0.3333333333333333)\n","(0.6844526218951242, 0.6838235294117647, array([0.65655172, 0.72413793, 0.6878453 ]), 0.3333333333333333)\n","(0.6927322907083716, 0.7150735294117647, nan, 0.0)\n","(0.6927322907083716, 0.7150735294117647, nan, 0.0)\n","(0.6922723091076357, 0.7150735294117647, nan, 0.0)\n","(0.6922723091076357, 0.7150735294117647, nan, 0.0)\n","(0.6922723091076357, 0.7150735294117647)\n"]}],"source":["import time\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import SGDClassifier, LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import VotingClassifier\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","d = pd.read_csv(\"https://raw.githubusercontent.com/maxleungtszchun/Statistical-Learning-with-customer-data/main/data/d.csv\", na_values = \"NA\")\n","train_d = d.sample(frac = 0.8, random_state = 5)\n","test_d = d.drop(train_d.index)\n","\n","train_X = train_d[[\"negative_r_zScore.x\", \"f_zScore.x\", \"m_zScore.x\"]]\n","test_X = test_d[[\"negative_r_zScore.x\", \"f_zScore.x\", \"m_zScore.x\"]]\n","\n","train_y = train_d[\"return.y\"]\n","test_y = test_d[\"return.y\"]\n","\n","def get_accuracy(clf, X, y, X_test, y_test):\n","    clf.fit(X, y)\n","    y_predict = clf.predict(X)\n","    in_sample_accu = np.mean(y_predict == y)\n","    y_test_predict = clf.predict(X_test)\n","    out_sample_accu = np.mean(y_test_predict == y_test)\n","    return in_sample_accu, out_sample_accu\n","\n","def build_model(X, y, X_test, y_test,\n","                loss = \"log\", penalty = \"l2\", alpha = 0.0001, l1_ratio = 0,\n","                cv_score = False, cv_num = 3,\n","                SGD = True, solver = \"lbfgs\",\n","                timer = False):\n","    # l1_ratio is not used except penalty == \"elasticnet\"\n","    start = time.time()\n","    if penalty not in [\"l1\", \"l2\", \"elasticnet\"]:\n","        raise Exception() # exclude penalty == \"none\" case for LogisticRegression()\n","    if SGD == True:\n","        learning_rate = \"optimal\"\n","        eta0 = 0\n","        if alpha == 0:\n","            learning_rate = \"constant\"\n","            eta0 = 0.1\n","        clf = SGDClassifier(loss = loss, penalty = penalty, alpha = alpha, l1_ratio = l1_ratio,\n","                            learning_rate = learning_rate, eta0 = eta0)\n","    else:\n","        if alpha == 0:\n","            penalty = \"none\"\n","            C = float(\"inf\")\n","        else:\n","            C = alpha ** -1\n","        clf = LogisticRegression(penalty = penalty, C = C, l1_ratio = l1_ratio, solver = solver, max_iter = 1000)\n","    in_sample_accu, out_sample_accu = get_accuracy(clf = clf, X = X, y = y, X_test = X_test, y_test = y_test)\n","    cv_accu = np.nan\n","    if cv_score == True:\n","        cv_accu = cross_val_score(clf, X, y, cv = cv_num, scoring = \"accuracy\")\n","    sparsity = np.mean(clf.coef_ == 0)\n","    if timer == True: print(\"%.2f mins\" % ((time.time() - start) / 60))\n","    return in_sample_accu, out_sample_accu, cv_accu, sparsity, clf\n","\n","# Unregularized Logistic Regression (SGD optimized)\n","# with shrinkage para. set to 0\n","print(build_model(train_X, train_y, test_X, test_y, alpha = 0, cv_score = True)[:-1])\n","\n","# L2 (Ridge-type) regularized Logistic Regression (SGD optimized)\n","# with shrinkage para. set to 0.0001\n","print(build_model(train_X, train_y, test_X, test_y, cv_score = True)[:-1])\n","\n","# L1 (Lasso-type) regularized Logistic Regression (SGD optimized)\n","# with shrinkage para. set to 0.0001\n","print(build_model(train_X, train_y, test_X, test_y, penalty = \"l1\", cv_score = True)[:-1])\n","\n","# Elastic-net Logistic Regression (SGD optimized)\n","# with shrinkage para. set to 0.0001\n","print(build_model(train_X, train_y, test_X, test_y, penalty = \"elasticnet\", l1_ratio = 0.5, cv_score = True)[:-1])\n","\n","\n","# Unregularized Logistic Regression (Quasi-Newton (LBFGS) optimized)\n","# with shrinkage para. set to 0\n","print(build_model(train_X, train_y, test_X, test_y, SGD = False, alpha = 0)[:-1])\n","\n","# L2 (Ridge-type) regularized Logistic Regression (Quasi-Newton (LBFGS) optimized)\n","# with shrinkage para. set to 0.0001\n","print(build_model(train_X, train_y, test_X, test_y, SGD = False)[:-1])\n","\n","# L1 (Lasso-type) regularized Logistic Regression (Saga optimized)\n","# with shrinkage para. set to 0.0001\n","print(build_model(train_X, train_y, test_X, test_y, SGD = False, penalty = \"l1\", solver = \"saga\")[:-1])\n","\n","# Elastic-net Logistic Regression (Saga optimized)\n","# with shrinkage para. set to 0.0001\n","print(build_model(train_X, train_y, test_X, test_y, SGD = False, penalty = \"elasticnet\", l1_ratio = 0.5, solver = \"saga\")[:-1])\n","\n","# Voting Classifier\n","voting_clf = VotingClassifier(\n","    estimators=[(\"logistic_reg_sgd\", build_model(train_X, train_y, test_X, test_y, alpha = 0, cv_score = True)[-1]),\n","                (\"l2_logistic_reg_sgd\", build_model(train_X, train_y, test_X, test_y, cv_score = True)[-1]),\n","                (\"l1_logistic_reg_sgd\", build_model(train_X, train_y, test_X, test_y, penalty = \"l1\", cv_score = True)[-1]),\n","                (\"elastic_net_logistic_reg_sgd\", build_model(train_X, train_y, test_X, test_y, penalty = \"elasticnet\", l1_ratio = 0.5, cv_score = True)[-1]),\n","                (\"logistic_reg_lbfgs\", build_model(train_X, train_y, test_X, test_y, SGD = False, alpha = 0)[-1]),\n","                (\"l2_logistic_reg_lbfgs\", build_model(train_X, train_y, test_X, test_y, SGD = False)[-1]),\n","                (\"l1_logistic_reg_saga\", build_model(train_X, train_y, test_X, test_y, SGD = False, penalty = \"l1\", solver = \"saga\")[-1]),\n","                (\"elastic_net_logistic_reg_saga\", build_model(train_X, train_y, test_X, test_y, SGD = False, penalty = \"elasticnet\", l1_ratio = 0.5, solver = \"saga\")[-1])],\n","    voting = \"hard\")\n","print(get_accuracy(voting_clf, train_X, train_y, test_X, test_y))\n"]}]}