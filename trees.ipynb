{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trees.ipynb","provenance":[],"authorship_tag":"ABX9TyPg14RWRC7HK74pa4e2liNC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98iULhSmJpcv","executionInfo":{"status":"ok","timestamp":1643263835614,"user_tz":-480,"elapsed":18089,"user":{"displayName":"Tsz Chun Leung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03041754811113981543"}},"outputId":"0b3543c1-5731-4e13-f3ff-e77efe16ebdb"},"outputs":[{"output_type":"stream","name":"stdout","text":["(0.7097516099356026, 0.7022058823529411)\n","(0.7203311867525299, 0.7205882352941176)\n","(0.6964121435142594, 0.7132352941176471)\n","(0.7115915363385464, 0.7205882352941176)\n","(0.7327506899724011, 0.6893382352941176)\n","(0.7161913523459061, 0.71875)\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n","\n","d = pd.read_csv(\"https://raw.githubusercontent.com/maxleungtszchun/Statistical-Learning-with-customer-data/main/data/d.csv\", na_values = \"NA\")\n","train_d = d.sample(frac = 0.8, random_state = 5)\n","test_d = d.drop(train_d.index)\n","\n","train_X = train_d[[\"negative_r_zScore.x\", \"f_zScore.x\", \"m_zScore.x\"]]\n","test_X = test_d[[\"negative_r_zScore.x\", \"f_zScore.x\", \"m_zScore.x\"]]\n","\n","train_y = train_d[\"return.y\"]\n","test_y = test_d[\"return.y\"]\n","\n","num_trees = 500\n","max_depth = 3\n","\n","def get_accuracy(clf, X, y, X_test, y_test):\n","    clf.fit(X, y)\n","    y_predict = clf.predict(X)\n","    in_sample_accu = np.mean(y_predict == y)\n","    y_test_predict = clf.predict(X_test)\n","    out_sample_accu = np.mean(y_test_predict == y_test)\n","    return in_sample_accu, out_sample_accu\n","\n","# Decision Tree\n","tree_clf = DecisionTreeClassifier(max_depth = max_depth)\n","print(get_accuracy(tree_clf, train_X, train_y, test_X, test_y))\n","\n","# Bagging\n","bag_clf = BaggingClassifier(\n","    DecisionTreeClassifier(max_depth = max_depth),\n","    n_estimators = num_trees,   # 500 trees / bootstrapped samples\n","    max_samples = len(train_y), # num. of obs. in each bootstrapped sample = num. of obs. in training data\n","    bootstrap = True,\n","    n_jobs = -1)                # using all CPUs\n","print(get_accuracy(bag_clf, train_X, train_y, test_X, test_y))\n","\n","# Bagging considers all features in each split\n","# Random Forest only considers a random subset of all features in each split (only using square root of all features)\n","bag_rnd_clf = BaggingClassifier(\n","    DecisionTreeClassifier(max_depth = max_depth, splitter = \"random\"),\n","    n_estimators = num_trees,\n","    max_samples = len(train_y),\n","    bootstrap = True,\n","    n_jobs = -1)\n","print(get_accuracy(bag_rnd_clf, train_X, train_y, test_X, test_y))\n","\n","# or using RandomForestClassifier() directly\n","rnf_clf = RandomForestClassifier(\n","    n_estimators = num_trees,\n","    max_depth = max_depth,\n","    # max_leaf_nodes = 2 ** max_depth,\n","    n_jobs = -1)\n","print(get_accuracy(rnf_clf, train_X, train_y, test_X, test_y))\n","\n","# AdaBoost\n","ada_clf = AdaBoostClassifier(\n","    DecisionTreeClassifier(max_depth = 1),\n","    n_estimators = num_trees,\n","    algorithm = \"SAMME.R\",\n","    learning_rate = 0.5)\n","print(get_accuracy(ada_clf, train_X, train_y, test_X, test_y))\n","\n","# Voting Classifier\n","voting_clf = VotingClassifier(\n","    estimators=[(\"tree_clf\", tree_clf),\n","                (\"bag_clf\", bag_clf),\n","                (\"bag_rnd_clf\", bag_rnd_clf),\n","                (\"rnf_clf\", rnf_clf),\n","                (\"ada_clf\", ada_clf)],\n","    voting = \"hard\")\n","print(get_accuracy(voting_clf, train_X, train_y, test_X, test_y))"]}]}