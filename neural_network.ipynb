{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPWv8pJoxtRYX5VMSGXTDcL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6JCsDuxMQTy","outputId":"3b943e38-574e-4f08-c07f-0e9df998774e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," batch_normalization_2 (Batc  (None, 3)                12        \n"," hNormalization)                                                 \n","                                                                 \n"," dense_3 (Dense)             (None, 64)                256       \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 64)               256       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 4,749\n","Trainable params: 4,615\n","Non-trainable params: 134\n","_________________________________________________________________\n","Epoch 1/15\n","55/55 [==============================] - 4s 17ms/step - loss: 1.0306 - accuracy: 0.5515 - val_loss: 0.5509 - val_accuracy: 0.7011\n","Epoch 2/15\n","55/55 [==============================] - 0s 8ms/step - loss: 0.8579 - accuracy: 0.5980 - val_loss: 0.5164 - val_accuracy: 0.7149\n","Epoch 3/15\n","55/55 [==============================] - 0s 8ms/step - loss: 0.7409 - accuracy: 0.6400 - val_loss: 0.5130 - val_accuracy: 0.7218\n","Epoch 4/15\n","55/55 [==============================] - 0s 8ms/step - loss: 0.7185 - accuracy: 0.6343 - val_loss: 0.5149 - val_accuracy: 0.7379\n","Epoch 5/15\n","55/55 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.6486"]}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow.keras as keras\n","from tensorflow.keras import layers\n","# import nni\n","\n","class build_nn():\n","    def __init__(self, num_neuron, drop_out_rate):\n","        self.num_neuron = num_neuron\n","        self.drop_out_rate = drop_out_rate\n","\n","    def __call__(self):\n","        m = keras.Sequential(\n","            [\n","                keras.Input(shape = 3),\n","                layers.BatchNormalization(),\n","                layers.Dense(self.num_neuron, activation = \"selu\", kernel_initializer = \"lecun_normal\"),\n","                layers.Dropout(self.drop_out_rate),\n","                layers.BatchNormalization(),\n","                layers.Dense(self.num_neuron, activation = \"selu\", kernel_initializer = \"lecun_normal\"),\n","                layers.Dropout(self.drop_out_rate),\n","                layers.Dense(1, activation = \"sigmoid\")\n","            ]\n","        )\n","        return m\n","\n","def plot_history(history):\n","    pd.DataFrame(history.history).plot(figsize = (8, 5))\n","    plt.grid(True)\n","    plt.gca().set_ylim(0.5, 1)\n","    plt.show()\n","\n","def run_nn(paras, graph = False):\n","    d = pd.read_csv(\"https://raw.githubusercontent.com/maxleungtszchun/Statistical-Learning-with-customer-data/main/data/d.csv\", na_values = \"NA\")\n","    train_d = d.sample(frac = 0.8, random_state = 5)\n","    test_d = d.drop(train_d.index)\n","\n","    train_X = train_d[[\"negative_r_zScore.x\", \"f_zScore.x\", \"m_zScore.x\"]]\n","    test_X = test_d[[\"negative_r_zScore.x\", \"f_zScore.x\", \"m_zScore.x\"]]\n","\n","    train_y = train_d[\"return.y\"]\n","    test_y = test_d[\"return.y\"]\n","\n","    model = build_nn(num_neuron = paras[\"num_neuron\"], drop_out_rate = paras[\"drop_out_rate\"])()\n","    model.summary()\n","    model.compile(loss = \"binary_crossentropy\",\n","                  optimizer = keras.optimizers.Nadam(learning_rate = paras[\"learning_rate\"]),\n","                  metrics = [\"accuracy\"])\n","    history = model.fit(train_X, train_y, batch_size = paras[\"batch_size\"], epochs = 15, validation_split = 0.2)\n","    if graph == True: plot_history(history = history)\n","    loss, accuracy = model.evaluate(test_X, test_y, verbose = 0)\n","    print(\"Test accuracy %s\" % accuracy)\n","    # nni.report_final_result(accuracy)\n","\n","if __name__ == \"__main__\":\n","    # found by using nni\n","    paras = {\n","        \"num_neuron\": 64,\n","        \"drop_out_rate\": 0.6569358164629767,\n","        \"learning_rate\": 0.001,\n","        \"batch_size\": 32\n","    }\n","    # paras = nni.get_next_parameter()\n","    run_nn(paras = paras, graph = True)"]}]}